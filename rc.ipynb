{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from imgaug import augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.patches as patches\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video config\n",
    "WIDTH = 100\n",
    "HEIGHT = 100\n",
    "DIM = 3\n",
    "X_DIM = 3\n",
    "\n",
    "WIDTH_FACTOR = 800 // WIDTH\n",
    "HEIGHT_FACTOR = 600 // HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN:\n",
    "    def __init__(self, input_size, reservoir_size, output_size, spectral_radius=0.9, alpha=0.99):\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.W_in = np.random.rand(reservoir_size, input_size + 1) - 0.5  # bias term\n",
    "        self.W_res = np.random.rand(reservoir_size, reservoir_size) - 0.5 # bias term\n",
    "        self.W_out = np.random.rand(output_size, reservoir_size) - 0.5    # bias term\n",
    "\n",
    "        self.W_res *= spectral_radius / np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
    "\n",
    "    def train(self, X_train, y_train, transient=100):\n",
    "        X_train = np.concatenate((np.ones((len(X_train), 1)), X_train), axis=1)  # Add bias term to input\n",
    "        X_res = np.zeros((len(X_train), self.reservoir_size))\n",
    "        x = np.zeros(self.reservoir_size)\n",
    "\n",
    "        for t in range(len(X_train)):\n",
    "            u = X_train[t]\n",
    "            x = (1 - self.alpha) * x + self.alpha * np.tanh(np.dot(self.W_in, u) + np.dot(self.W_res, x))\n",
    "            if t > transient:\n",
    "                X_res[t] = x\n",
    "\n",
    "        self.W_out = np.dot(np.linalg.pinv(X_res[transient:]), y_train[transient:])\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = np.concatenate((np.ones((len(X_test), 1)), X_test), axis=1)  # Add bias term to input\n",
    "        X_res = np.zeros((len(X_test), self.reservoir_size))\n",
    "        x = np.zeros(self.reservoir_size)\n",
    "\n",
    "        for t in range(len(X_test)):\n",
    "            u = X_test[t]\n",
    "            x = (1 - self.alpha) * x + self.alpha * np.tanh(np.dot(self.W_in, u) + np.dot(self.W_res, x))\n",
    "            X_res[t] = x\n",
    "\n",
    "        return np.dot(X_res, self.W_out)  # Transpose removed here\n",
    "    \n",
    "    def identity(self, x):\n",
    "        return softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes_from_array(video_path, bounding_boxes, output_video_path):\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create a VideoWriter object for AVI format\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Read each frame, draw bounding boxes, and write to output video\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extract coordinates for the current frame\n",
    "        if frame_count < len(bounding_boxes):\n",
    "            x, y = bounding_boxes[frame_count]\n",
    "            x, y = int(x), int(y)\n",
    "            width, height = 30, 30  # Assumed width and height\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release video capture and writer objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Bounding boxes added and new video saved to: {output_video_path}\")\n",
    "\n",
    "def read_png_image(file_path, i):\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    image_array = random_augment(file_path)\n",
    "    image_array = resize(image_array, (WIDTH , HEIGHT), anti_aliasing=True)\n",
    "\n",
    "    # Remove alpha channel\n",
    "    #image_array = np.flipud(image_array[:,:,:3])\n",
    "\n",
    "    number = int(file_name.split(\"_\")[1].split(\".\")[0])\n",
    "\n",
    "    df = pd.read_csv(f'assets/preprocessed_bb_coordinates/moving_circle_{i}.csv')\n",
    "    x = df['X-coordinate']\n",
    "    y = df['Y-coordinate']\n",
    "\n",
    "    return image_array/255.0, x[number]//WIDTH_FACTOR, y[number]//HEIGHT_FACTOR\n",
    "\n",
    "def plot_image(img, bb, save_path):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    x, y = (bb[0]-30)//WIDTH_FACTOR, (bb[1]-30)//HEIGHT_FACTOR\n",
    "    rect = patches.Rectangle((x, y), 10, 10, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Save the figure instead of showing it\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()  # Close the figure to free memory\n",
    "\n",
    "def zoom(image):\n",
    "  zoom = iaa.Affine(scale=(1, 1.3))\n",
    "  image = zoom.augment_image(image)\n",
    "  return image\n",
    "\n",
    "def pan(image):\n",
    "  pan = iaa.Affine(translate_percent={\"x\":(-0.08, 0.08), \"y\":(-0.08, 0.08)})\n",
    "  image = pan.augment_image(image)\n",
    "  return image\n",
    "\n",
    "def img_random_brightness(image):\n",
    "  # As of experience models recats better to darker immages\n",
    "  brightness = iaa.Multiply((0.2, 1.2))\n",
    "  image = brightness.augment_image(image)\n",
    "  return image\n",
    "\n",
    "def random_augment(image):\n",
    "  image = mpimg.imread(image)\n",
    "  if np.random.rand() < 0.5:\n",
    "    image = pan(image)\n",
    "  if np.random.rand() < 0.5:\n",
    "    image = zoom(image)\n",
    "  if np.random.rand() < 0.5:\n",
    "    image = img_random_brightness(image)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghorb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X = X / 255.0  # Normalize pixel values to range [0, 1]\n",
    "y = OneHotEncoder().fit_transform(y.values.reshape(-1, 1)).toarray()  # One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 784)\n",
      "y shape: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train ESN\n",
    "input_size = X_train.shape[1]\n",
    "reservoir_size = 1000\n",
    "output_size = 10\n",
    "esn = ESN(input_size, reservoir_size, output_size)\n",
    "esn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9207142857142857\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate\n",
    "predictions = esn.predict(X_test)\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Predicted label: [-0.05835204  0.04547256  0.1694305   0.07204689 -0.13773881  0.71455586\n",
      "  0.19365325 -0.01147344  0.11068185 -0.11049502]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground truth label:\", y_test[90])\n",
    "print(\"Predicted label:\", predictions[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities:   7\n",
      "ground truth label:        7\n"
     ]
    }
   ],
   "source": [
    "prediction_softmax = softmax(predictions[90])\n",
    "print(\"Predicted probabilities:  \", np.argmax(prediction_softmax))\n",
    "print(\"ground truth label:       \", np.argmax(y_test[90]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on shapes (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing images for shape: circle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images...: 100%|██████████| 4/4 [04:34<00:00, 68.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing images for shape: rect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images...: 100%|██████████| 3/3 [02:55<00:00, 58.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing images for shape: star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images...: 100%|██████████| 4/4 [04:37<00:00, 69.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load video frames\n",
    "shapes = {'circle':4, 'rect':3, 'star':4}\n",
    "#shapes = {'circle':1}\n",
    "X, y = [], []\n",
    "n = 0\n",
    "\n",
    "for j in shapes.keys():\n",
    "    print(f'Preprocessing images for shape: {j}')\n",
    "    for i in tqdm(range(shapes[j]), desc='Preprocessing images...'):\n",
    "        img_path = os.path.join(os.getcwd(), f'assets/original_frames/moving_{j}_{i}')\n",
    "        files = glob.glob(os.path.join(img_path, '*.png'))\n",
    "        sorted_files = sorted(files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "        for filepath in sorted_files:\n",
    "            image_array, _, _ = read_png_image(filepath, i)\n",
    "\n",
    "            X.append(image_array)\n",
    "            y.append(n)\n",
    "    n += 1\n",
    "\n",
    "print('Preprocessing done!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(X), np.array(y)\n",
    "X = np.reshape(X, (len(X), HEIGHT*WIDTH, DIM))\n",
    "X_gray = np.dot(X[...,:DIM], [0.2989, 0.5870, 0.1140])\n",
    "X = np.expand_dims(X_gray, axis=-1)\n",
    "\n",
    "y = OneHotEncoder().fit_transform(y.reshape(-1, 1)).toarray()  # One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "n_samples = len(X)\n",
    "train_idx = int(n_samples * 0.95)\n",
    "X_train, X_test = X[:train_idx,...], X[train_idx:, ...]\n",
    "y_train, y_test = y[:train_idx], y[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train ESN\n",
    "input_size = X_train.shape[1]\n",
    "reservoir_size = 2000\n",
    "output_size = 3\n",
    "esn = ESN(input_size, \n",
    "          reservoir_size, \n",
    "          output_size, \n",
    "          spectral_radius=0.9, \n",
    "          alpha=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn.train(np.array(X_train[:, :, 0]).reshape(len(X_train), -1), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4686868686868687\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate\n",
    "predictions = esn.predict(np.array(X_test[:, :, 0]).reshape(len(X_test), -1))\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth label: [0. 0. 1.]\n",
      "Predicted label: [ 1.09304253  0.21541754 -0.30851977]\n"
     ]
    }
   ],
   "source": [
    "TEST = 49\n",
    "print(\"Ground truth label:\", y_test[TEST])\n",
    "print(\"Predicted label:\", predictions[TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities:   0\n",
      "ground truth label:        2\n"
     ]
    }
   ],
   "source": [
    "prediction_softmax = softmax(predictions[TEST])\n",
    "print(\"Predicted probabilities:  \", np.argmax(prediction_softmax))\n",
    "print(\"ground truth label:       \", np.argmax(y_test[TEST]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
