{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from imgaug import augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cupy as np\n",
    "from scipy.special import softmax\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "#from src.pyESNN.pyESNcupy import ESN\n",
    "import imageio.v3 as iio\n",
    "from io import BytesIO \n",
    "import matplotlib.patches as patches\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.transform import resize\n",
    "from src.utils.path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUTS = 1000  # Number of input dimensions (in this case, grayscale pixel values)\n",
    "N_OUTPUTS = 2  # Number of output dimensions (x and y coordinates)\n",
    "N_RESERVOIR = 1000  # Increased number of reservoir neurons\n",
    "SPECTRAL_RADIUS = 0.8  # Adjusted spectral radius\n",
    "INPUT_SCALING = 0.7  # Adjusted input scaling\n",
    "NOISE = 0.1  # Reduced noise\n",
    "SPARSITY = 0.2  # Adjusted sparsity\n",
    "FEEDBACK_SCALING = 0.7  # Adjusted feedback scaling\n",
    "TEACHER_SCALING = 0.9  # Adjusted teacher scaling\n",
    "TEACHER_FORCING = True  # Use teacher forcing\n",
    "\n",
    "# video config\n",
    "WIDTH = 100\n",
    "HEIGHT = 100\n",
    "DIM = 3\n",
    "X_DIM = 3\n",
    "\n",
    "WIDTH_FACTOR = 800 // WIDTH\n",
    "HEIGHT_FACTOR = 600 // HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def generate_image_with_shape_and_bbox(shape_type, save_dir, bbox_file, index):\n",
    "    width, height = 100, 100\n",
    "\n",
    "    img = Image.new('RGB', (width, height), 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    x = random.randint(15, width - 45)\n",
    "    y = random.randint(15, height - 45)\n",
    "    size = random.randint(20, 40)\n",
    "\n",
    "    # Calculate center coordinates\n",
    "    center_x = x + size // 2\n",
    "    center_y = y + size // 2\n",
    "\n",
    "    # Draw the shape based on the shape type\n",
    "    if shape_type == 'circle':\n",
    "        draw.ellipse([(x, y), (x + size, y + size)], outline='black', width=2)\n",
    "    elif shape_type == 'triangle':\n",
    "        draw.polygon([(x, y), (x + size, y), (x + size // 2, y - size)], outline='black', width=2)\n",
    "    elif shape_type == 'rectangle':\n",
    "        draw.rectangle([(x, y), (x + size, y + size)], outline='black', width=2)\n",
    "\n",
    "\n",
    "    img.save(os.path.join(save_dir, f'{shape_type}_{index}.png'))\n",
    "\n",
    "    with open(bbox_file, 'a') as f:\n",
    "        f.write(f'{shape_type}_{index}.png,{center_x},{center_y}\\n')\n",
    "\n",
    "def main():\n",
    "    main_dir = 'assets/new_images_shape_bbox/images'\n",
    "    os.makedirs(main_dir, exist_ok=True)\n",
    "\n",
    "    bbox_dir = 'assets/new_images_shape_bbox/bounding_boxes'\n",
    "    os.makedirs(bbox_dir, exist_ok=True)\n",
    "    bbox_file = os.path.join(bbox_dir, 'bounding_boxes.csv')\n",
    "\n",
    "    with open(bbox_file, 'w') as f:\n",
    "        f.write('filename,x,y\\n')\n",
    "\n",
    "    shapes = ['circle', 'triangle', 'rectangle']\n",
    "\n",
    "    num_images_per_shape = 10\n",
    "\n",
    "    # Generate images for each shape\n",
    "    for shape in shapes:\n",
    "        # Directory for this shape\n",
    "        shape_dir = os.path.join(main_dir, shape)\n",
    "        os.makedirs(shape_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "        n = 0\n",
    "        for i in range(num_images_per_shape):\n",
    "            generate_image_with_shape_and_bbox(shape, shape_dir, bbox_file, n)\n",
    "            n += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN:\n",
    "    def __init__(self, input_size, reservoir_size, output_size, spectral_radius=0.9, alpha=0.99):\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.W_in = np.random.rand(reservoir_size, input_size + 1) - 0.5  # bias term\n",
    "        self.W_res = np.random.rand(reservoir_size, reservoir_size) - 0.5 # bias term\n",
    "        self.W_out = np.random.rand(output_size, reservoir_size) - 0.5    # bias term\n",
    "\n",
    "        self.W_res *= spectral_radius / np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
    "\n",
    "    def train(self, X_train, y_train, transient=100):\n",
    "        X_train = np.concatenate((np.ones((len(X_train), 1)), X_train), axis=1)  # Add bias term to input\n",
    "        X_res = np.zeros((len(X_train), self.reservoir_size))\n",
    "        x = np.zeros(self.reservoir_size)\n",
    "\n",
    "        for t in range(len(X_train)):\n",
    "            u = X_train[t]\n",
    "            x = (1 - self.alpha) * x + self.alpha * np.tanh(np.dot(self.W_in, u) + np.dot(self.W_res, x))\n",
    "            if t > transient:\n",
    "                X_res[t] = x\n",
    "\n",
    "        self.W_out = np.dot(np.linalg.pinv(X_res[transient:]), y_train[transient:])\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = np.concatenate((np.ones((len(X_test), 1)), X_test), axis=1)  # Add bias term to input\n",
    "        X_res = np.zeros((len(X_test), self.reservoir_size))\n",
    "        x = np.zeros(self.reservoir_size)\n",
    "\n",
    "        for t in range(len(X_test)):\n",
    "            u = X_test[t]\n",
    "            x = (1 - self.alpha) * x + self.alpha * np.tanh(np.dot(self.W_in, u) + np.dot(self.W_res, x))\n",
    "            X_res[t] = x\n",
    "\n",
    "        return np.dot(X_res, self.W_out)\n",
    "    \n",
    "    def identity(self, x):\n",
    "        return softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes_from_array(video_path, bounding_boxes, output_video_path):\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create a VideoWriter object for AVI format\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Read each frame, draw bounding boxes, and write to output video\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extract coordinates for the current frame\n",
    "        if frame_count < len(bounding_boxes):\n",
    "            x, y = bounding_boxes[frame_count]\n",
    "            x, y = int(x), int(y)\n",
    "            width, height = 30, 30  # Assumed width and height\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release video capture and writer objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Bounding boxes added and new video saved to: {output_video_path}\")\n",
    "\n",
    "def read_png_image(file_path, name, i):\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    image_array = random_augment(file_path)\n",
    "    image_array = resize(image_array, (WIDTH , HEIGHT), anti_aliasing=True)\n",
    "\n",
    "    # Remove alpha channel\n",
    "    #image_array = np.flipud(image_array[:,:,:3])\n",
    "\n",
    "    number = int(file_name.split(\"_\")[1].split(\".\")[0])\n",
    "\n",
    "    df = pd.read_csv(f'assets/new_images_shape_bbox/bounding_boxes.csv')\n",
    "    x = df['X-coordinate']\n",
    "    y = df['Y-coordinate']\n",
    "\n",
    "    return image_array/255.0, x[number]//WIDTH_FACTOR, y[number]//HEIGHT_FACTOR\n",
    "\n",
    "def plot_image(img, bb, save_path):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    x, y = (bb[0]-30)//WIDTH_FACTOR, (bb[1]-30)//HEIGHT_FACTOR\n",
    "    rect = patches.Rectangle((x, y), 10, 10, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    plt.close() \n",
    "\n",
    "def zoom(image):\n",
    "  zoom = iaa.Affine(scale=(1, 1.3))\n",
    "  image = zoom.augment_image(image)\n",
    "  return image\n",
    "\n",
    "def pan(image):\n",
    "  pan = iaa.Affine(translate_percent={\"x\":(-0.08, 0.08), \"y\":(-0.08, 0.08)})\n",
    "  image = pan.augment_image(image)\n",
    "  return image\n",
    "\n",
    "def img_random_brightness(image):\n",
    "  # As of experience models recats better to darker immages\n",
    "  brightness = iaa.Multiply((0.2, 1.2))\n",
    "  image = brightness.augment_image(image)\n",
    "  return image\n",
    "\n",
    "def random_augment(image):\n",
    "  image = mpimg.imread(image)\n",
    "  if np.random.rand() < 0.5:\n",
    "    image = pan(image)\n",
    "  if np.random.rand() < 0.5:\n",
    "    image = zoom(image)\n",
    "  if np.random.rand() < 0.5:\n",
    "    image = img_random_brightness(image)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = image_paths[random.randint(0, 35)]\n",
    "image = 'assets/original_frames/moving_circle_0/frame_0020.png'\n",
    "original_image = mpimg.imread(image)\n",
    "zoomed_image = zoom(original_image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.tight_layout()\n",
    "axs[0].imshow(original_image)\n",
    "axs[0].set_title('Original Image')\n",
    "\n",
    "axs[1].imshow(zoomed_image)\n",
    "axs[1].set_title('Zoomed Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'assets/original_frames/moving_circle_0/frame_0070.png'\n",
    "original_image = mpimg.imread(image)\n",
    "panned_image = pan(original_image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.tight_layout()\n",
    "\n",
    "axs[0].imshow(original_image)\n",
    "axs[0].set_title('Original Image')\n",
    "\n",
    "axs[1].imshow(panned_image)\n",
    "axs[1].set_title('Panned Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'assets/original_frames/moving_circle_0/frame_0090.png'\n",
    "original_image = mpimg.imread(image)\n",
    "brightness_altered_image = img_random_brightness(original_image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.tight_layout()\n",
    "\n",
    "axs[0].imshow(original_image)\n",
    "axs[0].set_title('Original Image')\n",
    "\n",
    "axs[1].imshow(brightness_altered_image)\n",
    "axs[1].set_title('brightness Altered Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all png files\n",
    "#shapes = {'circle':4, 'rect':3, 'star':4}\n",
    "shapes = {'circle':15}\n",
    "X, y_bb = [], []\n",
    "for j in shapes.keys():\n",
    "    for i in tqdm(range(shapes[j]), desc='Preprocessing images...'):\n",
    "        img_path = os.path.join(os.getcwd(), f'assets/original_frames/moving_{j}_{i}')\n",
    "        files = glob.glob(os.path.join(img_path, '*.png'))\n",
    "        sorted_files = sorted(files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "        for filepath in sorted_files:\n",
    "            image_array, x, y = read_png_image(filepath, j, i)\n",
    "\n",
    "            X.append(image_array)\n",
    "            y_bb.append([x, y])\n",
    "print('Preprocessing done!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_bb = np.array(X), np.array(y_bb)\n",
    "X = np.reshape(X, (len(X), HEIGHT*WIDTH, DIM))\n",
    "X_gray = np.dot(X[...,:DIM], np.array([0.2989, 0.5870, 0.1140]))\n",
    "X = np.expand_dims(X_gray, axis=-1)\n",
    "\n",
    "# Create MinMaxScaler for bounding box data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_bb = scaler.fit_transform(y_bb.get())\n",
    "\n",
    "print(f'shape of X: {X.shape}, shape of y_bb:{y_bb.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "n_samples = len(X)\n",
    "train_idx = int(n_samples * 0.98)\n",
    "X_train, X_test = X[:train_idx,...], X[train_idx:, ...]\n",
    "y_bb_train, y_bb_test = scaled_bb[:train_idx], scaled_bb[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build the model\n",
    "\"\"\"\n",
    "'''\n",
    "# Create the Echo State Network (ESN)\n",
    "esn = ESN(n_inputs=N_INPUTS, \n",
    "          n_outputs=N_OUTPUTS, \n",
    "          n_reservoir=N_RESERVOIR,\n",
    "          spectral_radius=SPECTRAL_RADIUS, \n",
    "          input_scaling=INPUT_SCALING,\n",
    "          noise=NOISE,\n",
    "          sparsity=SPARSITY,\n",
    "          feedback_scaling=FEEDBACK_SCALING,\n",
    "          teacher_scaling=TEACHER_SCALING,\n",
    "          teacher_forcing=TEACHER_FORCING, \n",
    "          silent=False)\n",
    "'''\n",
    "esn = ESN(input_size=N_INPUTS, \n",
    "          output_size=N_OUTPUTS, \n",
    "          reservoir_size=N_RESERVOIR,\n",
    "          alpha=1,\n",
    "          spectral_radius=SPECTRAL_RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn.fit(np.array(X_train).reshape(len(X_train), -1), np.array(y_bb_train))\n",
    "print('Model fitted!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on the entire video\n",
    "video_directory = os.path.join(ORIGINAL_VAL_VIDEOS_DIR, 'moving_circle_3.mp4')\n",
    "output_video_path = os.path.join(PREDICTED_VIDEOS_DIR, 'moving_circle_val_0.mp4')\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_directory)\n",
    "\n",
    "frames = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to PNG format in memory\n",
    "    with BytesIO() as f:\n",
    "        iio.imwrite(f, frame, format='png')\n",
    "        f.seek(0)\n",
    "        # Read PNG image from memory\n",
    "        image_array = iio.imread(f)\n",
    "\n",
    "    # Resize the image\n",
    "    image_array = resize(image_array, (WIDTH, HEIGHT), anti_aliasing=True)\n",
    "\n",
    "    # Append resized frame to frames list\n",
    "    frames.append(image_array/255.0)\n",
    "\n",
    "# Convert frames to numpy array\n",
    "frames = np.array(frames)\n",
    "frames = np.reshape(frames, (len(frames), HEIGHT*WIDTH, DIM))\n",
    "X_gray = np.dot(frames[...,:DIM], np.array([0.2989, 0.5870, 0.1140]))\n",
    "frames = np.expand_dims(X_gray, axis=-1)\n",
    "\n",
    "# Predict bounding box coordinates for the entire video\n",
    "predictions = esn.predict(frames.reshape(len(frames), -1))\n",
    "\n",
    "# Inverse min-max scaling\n",
    "predictions  = predictions.get()\n",
    "\n",
    "bb = scaler.inverse_transform(predictions)\n",
    "# abs to avoid negative values\n",
    "for i in range(len(bb)):\n",
    "    bb[i][0] = int(abs(bb[i][0]) * WIDTH_FACTOR)\n",
    "    bb[i][1] = int(abs(bb[i][1]) * HEIGHT_FACTOR)\n",
    "print(bb)\n",
    "\n",
    "# Release video capture object\n",
    "cap.release()\n",
    "\n",
    "# Draw bounding boxes on the video\n",
    "draw_bounding_boxes_from_array(video_directory, bb, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
